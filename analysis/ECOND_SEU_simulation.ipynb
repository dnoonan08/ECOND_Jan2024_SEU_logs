{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7c343-2ff1-4a43-b020-d70089c67ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load \"firstcell.py\"\n",
    "import numpy\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "np = numpy\n",
    "plt = pyplot\n",
    "\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "\n",
    "from pylab import *\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c9828-8d0b-4244-8848-50923ee95c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import awkward\n",
    "import json\n",
    "import bitstruct\n",
    "import crcmod\n",
    "import scipy.stats\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from ECOND_SEU import run_times, fluences, hexa42_files, hexprint, items, packet_parser, capture_batch, incident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c958cc-8ca6-449d-b475-cb9d37f3ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same as the `incident` class, except for how we provide the inputs\n",
    "class incident2:\n",
    "    def __init__(self, ASIC, EMU, cap_rows, packet, prebeam):\n",
    "        if packet == 255:\n",
    "            packet_rows = cap_rows\n",
    "        else:\n",
    "            packet_rows = (prebeam.packet_num == packet).nonzero()[0]\n",
    "        \n",
    "        first_row = min(cap_rows[0], packet_rows[0])\n",
    "        last_row = max(cap_rows[-1]+1, packet_rows[-1] + 1)\n",
    "        self.N_row = last_row - first_row\n",
    "        \n",
    "        self.prebeam_packet = prebeam.prebeam_data[first_row : last_row]\n",
    "        \n",
    "        self.ASIC_packet = zeros_like(self.prebeam_packet)\n",
    "        self.EMU_packet  = zeros_like(self.prebeam_packet)\n",
    "        self.ASIC_packet[cap_rows - first_row] = ASIC\n",
    "        self.EMU_packet [cap_rows - first_row] = EMU\n",
    "        \n",
    "        self.xor = self.ASIC_packet ^ self.EMU_packet\n",
    "        \n",
    "        self.cap = zeros_like(self.prebeam_packet, bool)\n",
    "        self.cap[cap_rows - first_row] = True\n",
    "        \n",
    "        self.gap = zeros_like(self.prebeam_packet, bool)\n",
    "        gap_indices = cap_rows - first_row + 4\n",
    "        gap_indices = gap_indices[gap_indices < (last_row - first_row)]\n",
    "        self.gap[gap_indices] = True\n",
    "        \n",
    "        self.known = self.cap | ~self.gap\n",
    "        self.mismatch = self.ASIC_packet != self.EMU_packet\n",
    "        code = prebeam.code_data[first_row : last_row]\n",
    "        subpack = prebeam.subpack[first_row : last_row]\n",
    "        subcode = prebeam.subcode[first_row : last_row]\n",
    "        subp_any = prebeam.subp_any[first_row : last_row]\n",
    "        \n",
    "        tri_logic = 1 * ~self.known + 2 * self.mismatch\n",
    "        \n",
    "        idle = tri_logic[code == 0].max(initial=0)\n",
    "        \n",
    "        packet_header_0 = tri_logic[code == 1].max(initial=0)\n",
    "        Payload_Length = any((self.xor[code == 1] & 0x007fc000) != 0) * packet_header_0\n",
    "        Header_Hamming = any((self.xor[code == 1] & 0x0000003f) != 0) * packet_header_0\n",
    "        \n",
    "        packet_header_1 = tri_logic[code == 2].max(initial=0)\n",
    "        L1A_orbit    = any((self.xor[code == 2] & 0x000ff800) != 0) * packet_header_1\n",
    "        Header_CRC   = any((self.xor[code == 2] & 0x000000ff) != 0) * packet_header_1\n",
    "        \n",
    "        Event_Header = max(any((self.xor[code == 1] & 0xff803fc0) != 0) * packet_header_0,\n",
    "                           any((self.xor[code == 2] & 0xfff00700) != 0) * packet_header_1)\n",
    "        \n",
    "        # Find which subpackets, if any, have some error, or even just unknowns\n",
    "        subpacket_errors = array([tri_logic[(subpack == i) & subp_any].max(initial=0) for i in range(12)])\n",
    "        \n",
    "        # Find the first subpacket, if any, that definitely has an error\n",
    "        if any(subpacket_errors == 2):\n",
    "            first_subpacket = (subpacket_errors == 2).nonzero()[0][0]\n",
    "        else:\n",
    "            first_subpacket = -1\n",
    "        \n",
    "        # Examine the headers and data of that first subpacket with an error\n",
    "        head0 = (subpack == first_subpacket) & ((subcode == 5) | (subcode == 7))\n",
    "        head1 = (subpack == first_subpacket) & (subcode == 6)\n",
    "        first_subp_head_0 = tri_logic[head0].max(initial=0)\n",
    "        first_subp_head_1 = tri_logic[head1].max(initial=0)\n",
    "        \n",
    "        first_subp_CRC   = any((self.xor[head0] & 0x20000000) != 0) * first_subp_head_0\n",
    "        first_subp_CM    = any((self.xor[head0] & 0x01ffffe0) != 0) * first_subp_head_0\n",
    "        first_subp_head  = any((self.xor[head0] & 0xde000000) != 0) * first_subp_head_0\n",
    "        first_subp_chmap = max(any((self.xor[head0] & 0x0000001f) != 0) * first_subp_head_0, first_subp_head_1)\n",
    "        first_subp_data = tri_logic[(subpack == first_subpacket) & (subcode == 8)].max(initial=0)\n",
    "            \n",
    "        # Check whether any later subpackets had errors, too\n",
    "        later_subp_errors = subpacket_errors[first_subpacket+1:].max(initial=0)\n",
    "        \n",
    "        # Packet CRC and Mandatory IDLE\n",
    "        CRC  = tri_logic[code == 3].max(initial=0)\n",
    "        Mand = tri_logic[code == 4].max(initial=0)\n",
    "\n",
    "        #                       13           12               11               10                  9               8\n",
    "        summary = array([first_subp_CRC, first_subp_CM, first_subp_head, first_subp_chmap, first_subp_data, later_subp_errors,\n",
    "                         Payload_Length, Header_Hamming, L1A_orbit, Header_CRC, Event_Header, CRC, Mand, idle])\n",
    "        #                        7            6              5           4          3          2     1     0\n",
    "        \n",
    "        self.pattern = int(sum(summary * 10**arange(summary.shape[0])[::-1]))\n",
    "        \n",
    "    def __str__(self):\n",
    "        outputs = []\n",
    "        with hexprint():\n",
    "            for row in range(self.N_row):\n",
    "                output_row = [self.prebeam_packet[row], ' ' if self.known[row].all() else 'G']\n",
    "                if self.cap[row].any():\n",
    "                    output_row.append(self.ASIC_packet[row])\n",
    "                    \n",
    "                if any(self.mismatch[row]):\n",
    "                    output_row.append(str(self.xor[row]).translate(str.maketrans({'0': '-'})))\n",
    "                outputs.append(' '.join([str(x) for x in output_row]))\n",
    "        return '\\n'.join(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede52adf-c967-4315-b580-123614bb2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only needs to be run once, to concatenate the original raw data\n",
    "# files, and to do a bit of processing to extract the fields packed\n",
    "# into the second \"counter\" link_capture channel.\n",
    "\n",
    "original_data_files_location = '/home/jsw/src/econd-sw'\n",
    "SEU_MC_file = '/home/jsw/src/econd-sw/SEU_MC_uint32.npz'\n",
    "\n",
    "if not pathlib.Path(SEU_MC_file).is_file():\n",
    "    ASIC = zeros((0, 6), dtype=uint32)\n",
    "    EMU = zeros((0, 6), dtype=uint32)\n",
    "    counter = zeros((0, 2), dtype=uint32)\n",
    "    for i in trange(12):\n",
    "        with np.load(pathlib.Path(original_data_files_location, f\"data_{i:d}.npz\")) as f:\n",
    "            ASIC    = concatenate([ASIC,    asarray(f['asic'],    uint32)])\n",
    "            EMU     = concatenate([EMU,     asarray(f['emu'],     uint32)])\n",
    "            counter = concatenate([counter, asarray(f['counter'], uint32)])\n",
    "\n",
    "    cutoff = (diff((counter[:,1] >> 22) & 0x3) == uint32(-3)).nonzero()[0][0] + 1\n",
    "\n",
    "    counter_raw = counter\n",
    "    counter = counter_raw[:,0]\n",
    "    error_bit  = asarray((counter_raw[:,1] >>  0) & ((1 <<  6) - 1), uint8)\n",
    "    error_word = asarray((counter_raw[:,1] >>  6) & ((1 <<  4) - 1), uint8)\n",
    "    error_BX   = asarray((counter_raw[:,1] >> 10) & ((1 << 12) - 1), uint16)\n",
    "    species    = asarray((counter_raw[:,1] >> 22) & ((1 <<  2) - 1), uint8)\n",
    "\n",
    "    splits = asarray(diff(counter_raw[:cutoff,1]).nonzero()[0]+1, uint32)\n",
    "\n",
    "    np.savez_compressed(SEU_MC_file,\n",
    "                        ASIC        = ASIC[:cutoff],\n",
    "                        EMU         = EMU[:cutoff],\n",
    "                        counter_raw = counter_raw[:cutoff],\n",
    "                        counter     = counter[:cutoff],\n",
    "                        error_bit   = error_bit[:cutoff],\n",
    "                        error_word  = error_word[:cutoff],\n",
    "                        error_BX    = error_BX[:cutoff],\n",
    "                        species     = species[:cutoff],\n",
    "                        splits      = splits)\n",
    "    \n",
    "    del ASIC, EMU, counter, cutoff, counter_raw, error_bit, error_word, error_BX, species, splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac56329-a93f-4768-906f-6cfa10d67680",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hexa_files_location = '/home/jsw/tmp/ECOND_Jan2024_SEU_logs/logs/'\n",
    "with open(pathlib.Path(hexa_files_location, hexa42_files[0])) as jsonfile:\n",
    "    J = json.load(jsonfile)\n",
    "    prebeam = packet_parser(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b0f9b1-67cd-4491-8093-bb419e078aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_capture_batches(k, ASIC, EMU, split_inds, percap, prebeam, swap=True):\n",
    "    start, end = split_inds_padded[[k, k+1]]\n",
    "    \n",
    "    if swap:\n",
    "        our_ASIC = EMU [start:end]\n",
    "        our_EMU  = ASIC[start:end]\n",
    "    else:\n",
    "        our_ASIC = ASIC[start:end]\n",
    "        our_EMU  = EMU [start:end]\n",
    "        \n",
    "    mismatch = any(our_ASIC ^ our_EMU, axis=1)\n",
    "    last_trigger = -inf\n",
    "    batches = []\n",
    "    for i in range(end-start):\n",
    "        if mismatch[i] and (i > last_trigger + percap):\n",
    "            # print(start+i-3, start+i-3+percap)\n",
    "            batches.append(capture_batch(our_ASIC[i-3 : i-3+percap],\n",
    "                                         our_EMU [i-3 : i-3+percap],\n",
    "                                         percap,\n",
    "                                         prebeam))\n",
    "            last_trigger = i\n",
    "            \n",
    "    return items(batches)\n",
    "\n",
    "def make_patt(k, ASIC, EMU, split_inds, percap, prebeam, swap=True):\n",
    "    batches = make_capture_batches(k, ASIC, EMU, split_inds, percap, prebeam, swap=True)\n",
    "    inc = incident(batches, percap, prebeam)\n",
    "    return inc.pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b646e70c-76fe-454e-b522-b49224edc925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gaps(mismatch, percap):\n",
    "    gap_stencil = arange(percap+1) > 0\n",
    "    old_gap = ones_like(mismatch)\n",
    "    new_gap = zeros_like(mismatch)\n",
    "    iteration = 0\n",
    "    while not all(old_gap == new_gap):\n",
    "        old_gap = new_gap\n",
    "        new_gap = convolve(mismatch & ~old_gap, gap_stencil)[:-percap]\n",
    "    return new_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193992a-f4df-4418-8ed2-da763639d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with np.load(SEU_MC_file) as f:\n",
    "    ASIC = f['ASIC']\n",
    "    EMU = f['EMU']\n",
    "    counter = f['counter']\n",
    "    counter_raw = f['counter_raw']\n",
    "    error_bit = f['error_bit']\n",
    "    error_word = f['error_word']\n",
    "    error_BX = f['error_BX']\n",
    "    species = f['species']\n",
    "    split_inds = f['splits']\n",
    "    split_inds_padded = append(insert(split_inds, 0, 0), ASIC.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5891d178-685c-4173-b517-c96a0f6abb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_lengths = awkward.run_lengths(counter_raw[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d720ad-a68a-43bc-a5b3-d897ed4d7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_bits = awkward.unflatten(error_bit, incident_lengths)[:,0].to_numpy()\n",
    "e_words = awkward.unflatten(error_word, incident_lengths)[:,0].to_numpy()\n",
    "e_BXs = awkward.unflatten(error_BX, incident_lengths)[:,0].to_numpy()\n",
    "e_specs = awkward.unflatten(species, incident_lengths)[:,0].to_numpy()\n",
    "ak_ASIC = awkward.unflatten(ASIC, incident_lengths)\n",
    "ak_EMU  = awkward.unflatten(EMU, incident_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada485e-bfd5-4f26-bb05-bee5da5548c6",
   "metadata": {},
   "source": [
    "# Find the captures\n",
    "\n",
    "For each simulated SEU, decide which of the rows that we actually captured would have been captured on Jan. 27, taking capture lengths (5 or 8 BX) and capture gaps / deadtime into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5945d-9fd9-4b74-b2e1-b01e60547678",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mismatch = any(ASIC != EMU, axis=1)\n",
    "\n",
    "gap5 = find_gaps(mismatch, 5)\n",
    "gap8 = find_gaps(mismatch, 8)\n",
    "\n",
    "cap5 = append(gap5[4:], zeros(4, bool))\n",
    "cap8 = append(gap8[4:], zeros(4, bool))\n",
    "\n",
    "incident_lengths5 = awkward.run_lengths(counter_raw[:,1][cap5])\n",
    "incident_lengths8 = awkward.run_lengths(counter_raw[:,1][cap8])\n",
    "\n",
    "ASIC8 = awkward.unflatten(ASIC[cap8], incident_lengths8)\n",
    "EMU8  = awkward.unflatten(EMU [cap8], incident_lengths8)\n",
    "\n",
    "ASIC5 = awkward.unflatten(ASIC[cap5], incident_lengths5)\n",
    "EMU5  = awkward.unflatten(EMU [cap5], incident_lengths5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1147b7a4-38b4-456e-9541-d1672eaee8da",
   "metadata": {},
   "source": [
    "# Find the prebeam indices\n",
    "\n",
    "Map the 32-bit counter onto the prebream data by unrolling its rollovers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbebcb67-9005-4ec9-b85a-49df8ff01f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_jump = cumsum(insert((diff(asarray(counter, int64)) < 0), 0, 0))\n",
    "counter_jump[6309470:] += 5 # This was inserted by hand to make it work out right -- here we apparently went several minutes with no recorded SEU\n",
    "unrolled_counter = (counter_jump * 2**32 + counter)\n",
    "prebeam_indices = (unrolled_counter - 67) % 3564 + 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d043b8be-475d-41fe-996f-495826bdeddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "packet = awkward.min(awkward.unflatten(prebeam.packet_num.min(axis=1)[prebeam_indices], incident_lengths), axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4e1428-6db7-4b96-93ed-dc4826de82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_rows5 = awkward.unflatten(prebeam_indices[cap5], incident_lengths5)\n",
    "first_row5 = cap_rows5[:,0].to_numpy()\n",
    "last_row5  = cap_rows5[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250fa98-74aa-4fce-8a73-3ce14cc3a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_rows8 = awkward.unflatten(prebeam_indices[cap8], incident_lengths8)\n",
    "first_row8 = cap_rows8[:,0].to_numpy()\n",
    "last_row8  = cap_rows8[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee59a6-902b-4962-9b40-ae09ca726c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "packet5 = awkward.min(awkward.unflatten(prebeam.packet_num.min(axis=1)[prebeam_indices[cap5]], incident_lengths5), axis=1).to_numpy(allow_missing=False)\n",
    "packet8 = awkward.min(awkward.unflatten(prebeam.packet_num.min(axis=1)[prebeam_indices[cap8]], incident_lengths8), axis=1).to_numpy(allow_missing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de84a1af-87cc-4388-a156-da2d9d212649",
   "metadata": {},
   "source": [
    "# False pileup\n",
    "\n",
    "Find the total number of possible false pileup events when capturing 8 or 5 BX at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19d4834-d116-4626-89b0-4299c753329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_double8 = zeros(67, uint64)\n",
    "for k in trange(67):\n",
    "    N_double8[k] = sum((first_row8[packet8 == k][:,newaxis] - last_row8[packet8 == k][newaxis,:]) > 0)\n",
    "sum(N_double8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af772abf-a5a4-46fe-af73-c960780f3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_double5 = zeros(67, uint64)\n",
    "for k in trange(67):\n",
    "    N_double5[k] = sum((first_row5[packet5 == k][:,newaxis] - last_row5[packet5 == k][newaxis,:]) > 0)\n",
    "sum(N_double5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b7688-2268-45e4-896a-0bb97eb9519a",
   "metadata": {},
   "source": [
    "Randomly sample from all possible false pileup events, and calculate the incident category for each one that we sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae78277-4ed5-4eab-89a4-387f679224c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "double_patt8 = []\n",
    "double_i8 = []\n",
    "double_j8 = []\n",
    "N = 100000\n",
    "prog = tqdm(total=N)\n",
    "while len(double_i8) < N:\n",
    "    i, j = randint(len(packet), size=2)\n",
    "    if i != j and packet8[i] == packet8[j] and packet8[i] != 255 and packet8[j] != 255:\n",
    "        if first_row8[j] > last_row8[i]:\n",
    "            inc = incident2(concatenate([ASIC8[i].to_numpy(),\n",
    "                                         ASIC8[j].to_numpy()]),\n",
    "                    concatenate([EMU8[i].to_numpy(),\n",
    "                                 EMU8[j].to_numpy()]),\n",
    "                    concatenate([cap_rows8[i].to_numpy(),\n",
    "                                 cap_rows8[j].to_numpy()]),\n",
    "                    packet[i],\n",
    "                    prebeam)\n",
    "            double_patt8.append(inc.pattern)\n",
    "            double_i8.append(i)\n",
    "            double_j8.append(j)\n",
    "            prog.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179a590-7942-4ebd-ab38-d92f4cb0982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "double_patt5 = []\n",
    "double_i5 = []\n",
    "double_j5 = []\n",
    "N = 100000\n",
    "prog = tqdm(total=N)\n",
    "while len(double_i5) < N:\n",
    "    i, j = randint(len(packet), size=2)\n",
    "    if i != j and packet5[i] == packet5[j] and packet5[i] != 255:\n",
    "        if first_row5[j] > last_row5[i]:\n",
    "            inc = incident2(concatenate([ASIC5[i].to_numpy(),\n",
    "                                         ASIC5[j].to_numpy()]),\n",
    "                    concatenate([EMU5[i].to_numpy(),\n",
    "                                 EMU5[j].to_numpy()]),\n",
    "                    concatenate([cap_rows5[i].to_numpy(),\n",
    "                                 cap_rows5[j].to_numpy()]),\n",
    "                    packet[i],\n",
    "                    prebeam)\n",
    "            double_patt5.append(inc.pattern)\n",
    "            double_i5.append(i)\n",
    "            double_j5.append(j)\n",
    "            prog.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3407c58-565d-4c8d-aad5-4a009c443bc8",
   "metadata": {},
   "source": [
    "Save the false pileup events to an output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c9203c-cffa-43fd-810c-9228c01dfb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "savez_compressed('false_pileup.npz',\n",
    "                 double_patt8=array(double_patt8, uint64), double_i8=array(double_i8, uint32), double_j8=array(double_j8, uint32), total8=array([N_double8], uint64),\n",
    "                 double_patt5=array(double_patt5, uint64), double_i5=array(double_i5, uint32), double_j5=array(double_j5, uint32), total5=array([N_double5], uint64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3851cc-f372-4e65-b1d1-b4e25653de4e",
   "metadata": {},
   "source": [
    "### Notes about how to normalize false pileup events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b49973-0cc8-47da-aec5-5eefd725667f",
   "metadata": {},
   "source": [
    "$$λ_\\text{orbit} = σ φ t_\\text{dwell}$$\n",
    "\n",
    "$$φ = \\frac{\\text{fluence}}{t_\\text{total}}$$\n",
    "\n",
    "$$λ = λ_\\text{orbit} \\frac{t_\\text{total}}{t_\\text{orbit}} = σ \\frac{t_\\text{dwell}}{t_\\text{orbit}} \\text{fluence}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c9863-c7bc-48b2-b1a9-d5d7377951ac",
   "metadata": {},
   "source": [
    "$$P(n=0) = e^{-λ}$$\n",
    "\n",
    "$$P(n=1) = λ e^{-λ}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b1aa68-0102-43b6-a286-604e53088bdd",
   "metadata": {},
   "source": [
    "$$P(\\text{fake pileup}) = P(\\text{1 event A}) \\left( \\sum_{n=0}^\\infty P(\\text{no events}) \\right) P(\\text{1 event B})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dcba8d-3ccb-48bd-9379-75fc768515b2",
   "metadata": {},
   "source": [
    "$$P(\\text{fake pileup}) = λ_A e^{-λ_A} λ_B e^{-λ_B} \\sum_{n=0}^\\infty \\left(e^{-λ_\\text{anything}}\\right)^n = λ_A λ_B e^{-λ_A} e^{-λ_B} \\frac{1}{1 - e^{-λ_\\text{anything}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7ccb8-9828-4826-8db9-bae4a62c1e25",
   "metadata": {},
   "source": [
    "$$e^{-ε} \\simeq 1 - ε$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d32d8-1288-4442-8d44-630b0289a3da",
   "metadata": {},
   "source": [
    "$$λ_\\text{fake pileup, orbit} \\simeq λ_A (1 - λ_A) λ_B (1 - λ_B) \\frac{1}{1 - (1 - λ_\\text{anything})} \\simeq λ_{A,\\text{orbit}} \\frac{λ_{B,\\text{orbit}}}{λ_\\text{anything,orbit}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be698db6-a885-48b2-aea1-c6c6dd6daca7",
   "metadata": {},
   "source": [
    "$$λ_\\text{fake pileup, orbit} = \\left(φ σ_i t_{i,\\text{dwell, A}}\\right) \\left(φ σ_i t_{i,\\text{dwell, B}}\\right) \\frac{1}{φ σ_i t_{i,\\text{dwell, anything}}}$$\n",
    "\n",
    "$$λ_\\text{fake pileup, orbit} = φ \\left(σ_i t_{i,\\text{dwell, A}}\\right) \\left(σ_i t_{i,\\text{dwell, B}}\\right) \\frac{1}{σ_i t_{i,\\text{dwell, anything}}}$$\n",
    "\n",
    "$$λ_\\text{fake pileup, orbit} = \\frac{\\text{fluence}}{t_\\text{total}} \\left(σ_i t_{i,\\text{dwell, A}}\\right) \\left(σ_i t_{i,\\text{dwell, B}}\\right) \\frac{1}{σ_i t_{i,\\text{dwell, anything}}}$$\n",
    "\n",
    "$$λ_\\text{fake pileup} = \\frac{\\text{fluence}}{t_\\text{orbit}} \\left(σ_i t_{i,\\text{dwell, A}}\\right) \\left(σ_i t_{i,\\text{dwell, B}}\\right) \\frac{1}{σ_i t_{i,\\text{dwell, anything}}}$$\n",
    "\n",
    "$$λ_\\text{fake pileup} = \\text{fluence} \\left(σ_i \\frac{t_{i,\\text{dwell, A}}}{t_\\text{orbit}}\\right) \\left(σ_i \\frac{t_{i,\\text{dwell, B}}}{t_\\text{orbit}}\\right) \\frac{1}{σ_i \\frac{t_{i,\\text{dwell, anything}}}{t_\\text{orbit}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a743fe2-dfbf-478e-8bdb-8453e97c2b4b",
   "metadata": {},
   "source": [
    "# Double-bit SEUs\n",
    "\n",
    "Currently only have this calculated for Output Buffer double-bit SEUs.  But we know they can affect the serializer, too.  So if we decide to use these in the analysis, we will need to calculate the serializer double-bit SEUs, too.  May need to give some thought to double-bit SEUs in the PP SRAM and the eRX, also.\n",
    "\n",
    "## Two-BX offset in Output Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104136a0-9fc4-462f-b416-bdf0092693bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "OB_xor = (ASIC8[e_specs == 2] ^ EMU8[e_specs == 2])\n",
    "offset_by_two_code = prebeam.code_data[cap_rows8[e_specs == 2] + 2][(OB_xor != 0)]\n",
    "newASIC8 = awkward.unflatten(awkward.flatten(ASIC8[e_specs==2]) ^ roll(awkward.flatten(OB_xor * (offset_by_two_code!=0)).to_numpy(), 2, axis=0), incident_lengths8[e_specs==2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d7a45-5a72-4867-b928-f690200879bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "OB_EMU8 = EMU8[e_specs == 2]\n",
    "OB_cap_rows8 = cap_rows8[e_specs==2]\n",
    "OB_packet = packet[e_specs==2]\n",
    "OBdouble_patt8 = [incident2(newASIC8[i].to_numpy(),\n",
    "          OB_EMU8[i].to_numpy(),\n",
    "          OB_cap_rows8[i].to_numpy(),\n",
    "          OB_packet[i],\n",
    "          prebeam).pattern for i in trange(sum(e_specs==2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4cc086-c455-4a44-9f06-b8d843e30366",
   "metadata": {},
   "source": [
    "## Two-bit offset in Output Buffer (capture 8 BX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202a529-c322-4646-8c43-afd881364512",
   "metadata": {},
   "outputs": [],
   "source": [
    "OB_xor8 = (ASIC8[e_specs == 2] ^ EMU8[e_specs == 2])\n",
    "OB_bit_offset_ASIC8 = awkward.unflatten(awkward.flatten(ASIC8[e_specs==2]) ^ awkward.flatten(OB_xor8 << 1).to_numpy(), incident_lengths8[e_specs==2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a73e87-4a63-4a35-9a3e-461fe43566db",
   "metadata": {},
   "outputs": [],
   "source": [
    "OB_EMU8 = EMU8[e_specs == 2]\n",
    "OB_cap_rows8 = cap_rows8[e_specs==2]\n",
    "OB_packet = packet[e_specs==2]\n",
    "OB_bit_offset_patt8 = [incident2(OB_bit_offset_ASIC8[i].to_numpy(),\n",
    "          OB_EMU8[i].to_numpy(),\n",
    "          OB_cap_rows8[i].to_numpy(),\n",
    "          OB_packet[i],\n",
    "          prebeam).pattern for i in trange(sum(e_specs==2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02bacd-1c4b-42c5-a4b2-28477d8a1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "OB_bit_offset_valid8 = awkward.any(awkward.all(OB_xor8 != 2**31, axis=1), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b312be8-d89c-4103-9dab-eb74fa4a9f18",
   "metadata": {},
   "source": [
    "## Two-bit offset in Output Buffer (capture 5 BX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35fcac0-4d38-4838-a962-2aba200f59c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OB_xor5 = (ASIC5[e_specs == 2] ^ EMU5[e_specs == 2])\n",
    "OB_bit_offset_ASIC5 = awkward.unflatten(awkward.flatten(ASIC5[e_specs==2]) ^ awkward.flatten(OB_xor5 << 1).to_numpy(), incident_lengths5[e_specs==2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac2bcb4-c770-40a5-9365-d8b0fbfe1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "OB_EMU5 = EMU5[e_specs == 2]\n",
    "OB_cap_rows5 = cap_rows5[e_specs==2]\n",
    "OB_packet = packet[e_specs==2]\n",
    "OB_bit_offset_patt5 = [incident2(OB_bit_offset_ASIC5[i].to_numpy(),\n",
    "          OB_EMU5[i].to_numpy(),\n",
    "          OB_cap_rows5[i].to_numpy(),\n",
    "          OB_packet[i],\n",
    "          prebeam).pattern for i in trange(sum(e_specs==2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebb0ca-38ae-4929-ba11-647652c8ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OB_bit_offset_valid5 = awkward.any(awkward.all(OB_xor5 != 2**31, axis=1), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e6265-47cc-4717-885b-177f3e619f93",
   "metadata": {},
   "source": [
    "Save the double-bit SEU events to a file.\n",
    "\n",
    "Currently, these are not used in the analysis, but they could be added in the future if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db64c8c2-891c-480b-9566-7af1293cfcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "savez_compressed('OB_double_SEU.npz',\n",
    "                 OB_BX_offset_patt8=OBdouble_patt8,\n",
    "                 OB_bit_offset_patt8=OB_bit_offset_patt8, OB_bit_offset_valid8=OB_bit_offset_valid8,\n",
    "                 OB_bit_offset_patt5=OB_bit_offset_patt5, OB_bit_offset_valid5=OB_bit_offset_valid5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5158658-b607-480e-b361-06551d6e2134",
   "metadata": {},
   "source": [
    "# BX frequency by SEU type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4938d12b-4071-4390-a68c-8a8fc681a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c,e,a = hist(e_BXs[e_specs == 0], bins=arange(3565)-0.5)\n",
    "xlim(-0.5, 3563.5)\n",
    "xlabel('BX')\n",
    "ylabel('eRX errors recorded per BX')\n",
    "tight_layout()\n",
    "savefig('eRX_per_BX.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ec1019-7cf5-46c7-a56e-04fee1a97f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c,e,a = hist(e_BXs[e_specs == 1], bins=arange(3565)-0.5)\n",
    "xlim(-0.5, 3563.5)\n",
    "xlabel('BX')\n",
    "ylabel('PP errors recorded per BX')\n",
    "tight_layout()\n",
    "savefig('PP_per_BX.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6848cef-5189-4a7b-aa76-5ff558c855c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c,e,a = hist(e_BXs[e_specs == 2], bins=arange(3565)-0.5)\n",
    "xlim(-0.5, 3563.5)\n",
    "xlabel('BX')\n",
    "ylabel('OB errors recorded per BX')\n",
    "tight_layout()\n",
    "savefig('OB_per_BX.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4438dd7d-e13d-41fa-836b-edb2de167f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c,e,a = hist(e_BXs[e_specs == 3], bins=arange(3565)-0.5)\n",
    "xlim(-0.5, 3563.5)\n",
    "xlabel('BX')\n",
    "ylabel('eTX errors recorded per BX')\n",
    "tight_layout()\n",
    "savefig('eTX_per_BX.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4422169-9076-44e4-9c3d-cd852a4140d2",
   "metadata": {},
   "source": [
    "# Regular SEUs\n",
    "\n",
    "Here we calculate the incident category for every simulated SEU.  It takes a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bd3e0-51e4-4339-b911-db6f4ae63d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all5 = zeros(len(e_bits), dtype=uint64)\n",
    "all8 = zeros(len(e_bits), dtype=uint64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a7b5e-f23f-48be-8cc5-b967b1735107",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in tqdm(arange(len(e_bits))[all5 == 0]):\n",
    "    all5[k] = incident2(ASIC5[k].to_numpy(),\n",
    "                        EMU5[k].to_numpy(),\n",
    "                        cap_rows5[k].to_numpy(),\n",
    "                        packet[k],\n",
    "                        prebeam).pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762f764-dbb8-494b-b559-dcb6d53b7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in tqdm(arange(len(e_bits))[all8 == 0]):\n",
    "    all8[k] = incident2(ASIC8[k].to_numpy(),\n",
    "                        EMU8[k].to_numpy(),\n",
    "                        cap_rows8[k].to_numpy(),\n",
    "                        packet[k],\n",
    "                        prebeam).pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33382db-0355-489c-9b2e-d28a5912090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('all58.npz', all5=all5, all8=all8, e_bits=e_bits, e_words=e_words, e_BXs=e_BXs, e_specs=e_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00384a1-1482-4646-b7fb-b7c040f41cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique(all5).shape[0], unique(all8).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b0863-8558-4e5c-aeb1-119689937cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "patt, c = unique(all5, return_counts=True)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27303c4-7563-407b-8565-dcad31b5308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patt, c = unique(all8, return_counts=True)\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coffea]",
   "language": "python",
   "name": "conda-env-coffea-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
